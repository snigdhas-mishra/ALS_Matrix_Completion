{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5229d70d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "602b18e8",
   "metadata": {},
   "source": [
    "## Matrix completion using Alternating Minimization with Gradient Descent. \n",
    "### Uses Alternating Least Squares and Gradient Descent with decaying learning rate. Gradient Descent is implimented using autograd package (numpy). \n",
    "### File : mat_completion/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78f39c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Either the m or n value or the demo observed_fraction is missing. Using random values to run the demo.\n",
      "\n",
      "STARTING DEMO ..... \n",
      "\n",
      "Running the matrix completion demo.\n",
      "We will generate a random matrix of size M= [325x76], with 8 non-zero singular values (True SVD rank).\n",
      "0.7740943837811604 fraction of [325x76] entries will be masked out to simulate a partially observed matrix.\n",
      "We will use ALS procedure to estimate matrices U and V, such that ||M - U*transpose(V)||^2 is minimum.  will reconstruct the fully observed matrix.\n",
      "U and V will have rank equal to the user input --rank parameter =5.\n",
      "We will then compare the difference between the true unobserved entries of M and the predictions to validate our method.\n",
      "\n",
      "STARTING TRAINING ..... \n",
      "\n",
      "\t TRAINING: ALS STEP: 0 / 50\n",
      "\t TRAINING:\t\tU step initial loss 1.4161001298429605\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 1.372208485376069\n",
      "\t TRAINING:\t\tV step initial loss 1.3751479383495382\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 1.244079951685868\n",
      "\t TRAINING: ALS STEP: 1 / 50\n",
      "\t TRAINING:\t\tU step initial loss 1.2264316846457262\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 1.183769758621652\n",
      "\t TRAINING:\t\tV step initial loss 1.197845859408365\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 1.107575948679064\n",
      "\t TRAINING: ALS STEP: 2 / 50\n",
      "\t TRAINING:\t\tU step initial loss 1.0795896189677783\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 1.0396285722730252\n",
      "\t TRAINING:\t\tV step initial loss 1.0642039590471102\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 1.0021861489607504\n",
      "\t TRAINING: ALS STEP: 3 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.9652208416115249\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.9287231024954308\n",
      "\t TRAINING:\t\tV step initial loss 0.9625683826647492\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.9199509502163619\n",
      "\t TRAINING: ALS STEP: 4 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.8755460838692036\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.8427691880791477\n",
      "\t TRAINING:\t\tV step initial loss 0.88440065633441\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.8549906093215118\n",
      "\t TRAINING: ALS STEP: 5 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.8046784489946638\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.7755653398527289\n",
      "\t TRAINING:\t\tV step initial loss 0.8234595810334087\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.8029748227553308\n",
      "\t TRAINING: ALS STEP: 6 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.7481731545164733\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.722493746944761\n",
      "\t TRAINING:\t\tV step initial loss 0.7752143339081647\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.7607303934786547\n",
      "\t TRAINING: ALS STEP: 7 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.7026898494832055\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.6801340660812557\n",
      "\t TRAINING:\t\tV step initial loss 0.7363975242856676\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.7259396426731928\n",
      "\t TRAINING: ALS STEP: 8 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.665726308883795\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.6459599958949667\n",
      "\t TRAINING:\t\tV step initial loss 0.7046618424405564\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.696909162122175\n",
      "\t TRAINING: ALS STEP: 9 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.635408387542447\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.6181042918050621\n",
      "\t TRAINING:\t\tV step initial loss 0.6783204900986981\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.6723959193023701\n",
      "\t TRAINING: ALS STEP: 10 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.6103276013764083\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.5951809140733046\n",
      "\t TRAINING:\t\tV step initial loss 0.6561555113977303\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.65147943280693\n",
      "\t TRAINING: ALS STEP: 11 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.5894184261545065\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.5761533374246823\n",
      "\t TRAINING:\t\tV step initial loss 0.6372794443859032\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.633469673020553\n",
      "\t TRAINING: ALS STEP: 12 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.5718674253231761\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.5602387127114395\n",
      "\t TRAINING:\t\tV step initial loss 0.6210373071955209\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.6178416909360248\n",
      "\t TRAINING: ALS STEP: 13 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.5570469014057252\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.5468389316025621\n",
      "\t TRAINING:\t\tV step initial loss 0.6069380955041296\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.6041896521145944\n",
      "\t TRAINING: ALS STEP: 14 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.5444668521453316\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.5354913503785679\n",
      "\t TRAINING:\t\tV step initial loss 0.5946073034391735\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.5921946401028281\n",
      "\t TRAINING: ALS STEP: 15 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.5337402776041105\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.5258336120282384\n",
      "\t TRAINING:\t\tV step initial loss 0.583754125050117\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.5816020748702035\n",
      "\t TRAINING: ALS STEP: 16 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.5245580782525491\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.5175784587499502\n",
      "\t TRAINING:\t\tV step initial loss 0.574148765876883\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.5722057795383316\n",
      "\t TRAINING: ALS STEP: 17 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.5166707854192074\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.5104955808175651\n",
      "\t TRAINING:\t\tV step initial loss 0.5656066582835476\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.5638366242691595\n",
      "\t TRAINING: ALS STEP: 18 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.5098751458883808\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.5043984153250706\n",
      "\t TRAINING:\t\tV step initial loss 0.5579773737512921\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.5563543233433434\n",
      "\t TRAINING: ALS STEP: 19 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.5040041621730493\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.499134437079447\n",
      "\t TRAINING:\t\tV step initial loss 0.5511367327527085\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.5496414153977289\n",
      "\t TRAINING: ALS STEP: 20 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.49891960720288125\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.49457792854504457\n",
      "\t TRAINING:\t\tV step initial loss 0.5449811014229022\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.543598768730589\n",
      "\t TRAINING: ALS STEP: 21 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4945063263194258\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.49062452524430067\n",
      "\t TRAINING:\t\tV step initial loss 0.5394231960056207\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.5381421650588669\n",
      "\t TRAINING: ALS STEP: 22 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.49066784432197036\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4871870464816228\n",
      "\t TRAINING:\t\tV step initial loss 0.5343889387901204\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.5331996573272288\n",
      "\t TRAINING: ALS STEP: 23 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4873229371061035\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4841922678794276\n",
      "\t TRAINING:\t\tV step initial loss 0.529815057782655\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.5287094924684974\n",
      "\t TRAINING: ALS STEP: 24 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4844029254774474\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4815783929259962\n",
      "\t TRAINING:\t\tV step initial loss 0.5256472210988232\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.5246184538967331\n",
      "\t TRAINING: ALS STEP: 25 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.48184951669710996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4792930501393388\n",
      "\t TRAINING:\t\tV step initial loss 0.5218385627212548\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.520880521496821\n",
      "\t TRAINING: ALS STEP: 26 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.47961306672330495\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4772916905692209\n",
      "\t TRAINING:\t\tV step initial loss 0.5183485000635352\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.5174557759946775\n",
      "\t TRAINING: ALS STEP: 27 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.47765116945624175\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.47553629399322567\n",
      "\t TRAINING:\t\tV step initial loss 0.5151417731670493\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.514309494513392\n",
      "\t TRAINING: ALS STEP: 28 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4759275029855203\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.47399431590508256\n",
      "\t TRAINING:\t\tV step initial loss 0.5121876552415047\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.5114113979167405\n",
      "\t TRAINING: ALS STEP: 29 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4744108798699362\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.47263782434049406\n",
      "\t TRAINING:\t\tV step initial loss 0.5094592978618748\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.5087350202344527\n",
      "\t TRAINING: ALS STEP: 30 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.47307446087413013\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.47144278782727644\n",
      "\t TRAINING:\t\tV step initial loss 0.5069331835620203\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.5062571773842087\n",
      "\t TRAINING: ALS STEP: 31 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4718951007222686\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.47038848469912725\n",
      "\t TRAINING:\t\tV step initial loss 0.5045886651986278\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.5039575174322314\n",
      "\t TRAINING: ALS STEP: 32 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4708528012483949\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4694570106413183\n",
      "\t TRAINING:\t\tV step initial loss 0.5024075762045516\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.5018181383507984\n",
      "\t TRAINING: ALS STEP: 33 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.46993025247633885\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4686328663054195\n",
      "\t TRAINING:\t\tV step initial loss 0.5003738993057255\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.4998232620271088\n",
      "\t TRAINING: ALS STEP: 34 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4691124461018744\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4679026105986249\n",
      "\t TRAINING:\t\tV step initial loss 0.4984734838370207\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.4979589554171915\n",
      "\t TRAINING: ALS STEP: 35 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4683863488948792\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.46725456814334687\n",
      "\t TRAINING:\t\tV step initial loss 0.49669380372503974\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.49621289140090363\n",
      "\t TRAINING: ALS STEP: 36 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.46774062591652166\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4666785816424087\n",
      "\t TRAINING:\t\tV step initial loss 0.4950237496890804\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.4945741432041967\n",
      "\t TRAINING: ALS STEP: 37 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4671654053195368\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.46616580163754195\n",
      "\t TRAINING:\t\tV step initial loss 0.49345345036791866\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.4930330073002799\n",
      "\t TRAINING: ALS STEP: 38 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.46665207798771136\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4657085075321753\n",
      "\t TRAINING:\t\tV step initial loss 0.4919741179945708\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.49158085054467926\n",
      "\t TRAINING: ALS STEP: 39 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.46619312646184663\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.46529995485024306\n",
      "\t TRAINING:\t\tV step initial loss 0.4905779149735514\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.49020997798585\n",
      "\t TRAINING: ALS STEP: 40 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4657819785594076\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.46493424458508653\n",
      "\t TRAINING:\t\tV step initial loss 0.4892578383080333\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.4889135183565283\n",
      "\t TRAINING: ALS STEP: 41 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4654128818734244\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4646062112045158\n",
      "\t TRAINING:\t\tV step initial loss 0.4880076193088025\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.48768532471655296\n",
      "\t TRAINING: ALS STEP: 42 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4650807959708256\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.46431132645610484\n",
      "\t TRAINING:\t\tV step initial loss 0.48682163641592535\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.4865198881046851\n",
      "\t TRAINING: ALS STEP: 43 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4647812996303832\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4640456165885874\n",
      "\t TRAINING:\t\tV step initial loss 0.48569483929489277\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.48541226237982704\n",
      "\t TRAINING: ALS STEP: 44 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.46451051088845996\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4638055909922591\n",
      "\t TRAINING:\t\tV step initial loss 0.4846226826448352\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.4843579987026833\n",
      "\t TRAINING: ALS STEP: 45 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.46426501801452147\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4635881805802242\n",
      "\t TRAINING:\t\tV step initial loss 0.48360106838747946\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.483353088336518\n",
      "\t TRAINING: ALS STEP: 46 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4640418198318613\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4633906844962448\n",
      "\t TRAINING:\t\tV step initial loss 0.4826262950998436\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.48239391263770137\n",
      "\t TRAINING: ALS STEP: 47 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4638382740433289\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.46321072395416557\n",
      "\t TRAINING:\t\tV step initial loss 0.4816950137176781\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.4814771992691494\n",
      "\t TRAINING: ALS STEP: 48 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4636520524259059\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.46304620219661385\n",
      "\t TRAINING:\t\tV step initial loss 0.48080418867545777\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.4805999838074733\n",
      "\t TRAINING: ALS STEP: 49 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.46348110192890585\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4628952697134803\n",
      "\t TRAINING:\t\tV step initial loss 0.4799510637665203\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.47975957603164165\n",
      "DEMO RESULTS\n",
      "Avg. Reconstruction loss on the observed matrix entries before training (with random U and V) =1.0816334632716427\n",
      "Avg. Reconstruction loss on the observed matrix entries after training (with trained U and V) =0.0925328386502223\n",
      "VALIDATION: Avg. Reconstruction loss on the unobserved matrix entries before training (with random U and V) =1.0926600642716946\n",
      "VALIDATION: Avg. Reconstruction loss on the unobserved matrix entries after training (with trained U and V) =0.1116866934762641\n",
      "VALIDATION: Avg. Reconstruction loss on the all matrix entries before training (with random U and V) =1.0901694809931808\n",
      "VALIDATION: Avg. Reconstruction loss on the all matrix entries after training (with trained U and V) =0.10736040375664925\n",
      "Saving the processed matrices in demo_out.npz\n"
     ]
    }
   ],
   "source": [
    "%run main.py --run_demo --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf7df56",
   "metadata": {},
   "source": [
    "## Sampling from Intersection of two n-dimensional spherical shell.\n",
    "### Uses numpy and autograd for optimization. Uses Matplotlib to plot the 3-D case. \n",
    "### File : gd_solver.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82a3a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
