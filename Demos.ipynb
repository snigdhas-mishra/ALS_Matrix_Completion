{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "602b18e8",
   "metadata": {},
   "source": [
    "## Matrix completion using Alternating Minimization with Gradient Descent. \n",
    "#### Uses Alternating Least Squares and Gradient Descent with decaying learning rate. Gradient Descent is implimented using autograd package (numpy). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae58e58",
   "metadata": {},
   "source": [
    "### Running in Verbose Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78f39c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Either the m or n value or the demo observed_fraction is missing. Using random values to run the demo.\n",
      "\n",
      "STARTING DEMO ..... \n",
      "\n",
      "Running the matrix completion demo.\n",
      "We will generate a random matrix of size M= [670x91], with 5 non-zero singular values (True SVD rank).\n",
      "0.18759268696537135 fraction of [670x91] entries will be masked out to simulate a partially observed matrix.\n",
      "We will use ALS procedure to estimate matrices U and V, such that ||M - U*transpose(V)||^2 is minimum.  will reconstruct the fully observed matrix.\n",
      "U and V will have rank equal to the user input --rank parameter =5.\n",
      "We will then compare the difference between the true unobserved entries of M and the predictions to validate our method.\n",
      "\n",
      "STARTING TRAINING ..... \n",
      "\n",
      "\t TRAINING: ALS STEP: 0 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.7969980083277953\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.7847691159806945\n",
      "\t TRAINING:\t\tV step initial loss 0.7881424590675059\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.7168417163807506\n",
      "\t TRAINING: ALS STEP: 1 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.732976370331831\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.7227197403821178\n",
      "\t TRAINING:\t\tV step initial loss 0.7090154387379459\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.6575812875534628\n",
      "\t TRAINING: ALS STEP: 2 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.6866814717190493\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.6777241092829329\n",
      "\t TRAINING:\t\tV step initial loss 0.6506517944074034\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.6130982105931968\n",
      "\t TRAINING: ALS STEP: 3 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.6524764893880934\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.6444233125874086\n",
      "\t TRAINING:\t\tV step initial loss 0.6067711471425016\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.5790039406075245\n",
      "\t TRAINING: ALS STEP: 4 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.6266093616057538\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.6192195686995643\n",
      "\t TRAINING:\t\tV step initial loss 0.5731110768548675\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.5522984191355049\n",
      "\t TRAINING: ALS STEP: 5 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.6065462898058611\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.5996674468755867\n",
      "\t TRAINING:\t\tV step initial loss 0.546740250088256\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.5309061146390398\n",
      "\t TRAINING: ALS STEP: 6 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.5905574354656806\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.5840893131758733\n",
      "\t TRAINING:\t\tV step initial loss 0.5256214429393884\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.5133771852246074\n",
      "\t TRAINING: ALS STEP: 7 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.5774521541230078\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.5713263336586842\n",
      "\t TRAINING:\t\tV step initial loss 0.508326673896978\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.49869070157139295\n",
      "\t TRAINING: ALS STEP: 8 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.5664059568070631\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.5605740135297091\n",
      "\t TRAINING:\t\tV step initial loss 0.49384780822092633\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.4861227556920704\n",
      "\t TRAINING: ALS STEP: 9 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.5568453726321589\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.551271841807201\n",
      "\t TRAINING:\t\tV step initial loss 0.48146863855712196\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.47515679835499924\n",
      "\t TRAINING: ALS STEP: 10 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.5483702423255012\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.543028315755667\n",
      "\t TRAINING:\t\tV step initial loss 0.4706773960989582\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.46542199253772665\n",
      "\t TRAINING: ALS STEP: 11 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.5407006879062745\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.5355695080002154\n",
      "\t TRAINING:\t\tV step initial loss 0.46110631343060665\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.45665044623726014\n",
      "\t TRAINING: ALS STEP: 12 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.533640610268463\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.5287035214589402\n",
      "\t TRAINING:\t\tV step initial loss 0.4524895415104845\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.44864732901868687\n",
      "\t TRAINING: ALS STEP: 13 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.527052398737304\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.5222957869226353\n",
      "\t TRAINING:\t\tV step initial loss 0.4446336601450516\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.4412698702750531\n",
      "\t TRAINING: ALS STEP: 14 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.5208393235257339\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.5162518257687481\n",
      "\t TRAINING:\t\tV step initial loss 0.43739690746561577\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.43441253029057064\n",
      "\t TRAINING: ALS STEP: 15 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.514933234605758\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.510505187835426\n",
      "\t TRAINING:\t\tV step initial loss 0.4306744896559505\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.4279964895203852\n",
      "\t TRAINING: ALS STEP: 16 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.5092859480911415\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.5050089959075311\n",
      "\t TRAINING:\t\tV step initial loss 0.42438815542838915\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.42196217463985586\n",
      "\t TRAINING: ALS STEP: 17 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.5038632070621601\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.49973001364105657\n",
      "\t TRAINING:\t\tV step initial loss 0.41847877585037596\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.4162639293154617\n",
      "\t TRAINING: ALS STEP: 18 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.49864044591095324\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4946444841135792\n",
      "\t TRAINING:\t\tV step initial loss 0.4129010500726328\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.4108662049697889\n",
      "\t TRAINING: ALS STEP: 19 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4935998211745163\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.48973521316360724\n",
      "\t TRAINING:\t\tV step initial loss 0.4076197195290646\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.40574083188513244\n",
      "\t TRAINING: ALS STEP: 20 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.48872813307786783\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4849895288078113\n",
      "\t TRAINING:\t\tV step initial loss 0.4026068552434986\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.4008650600046622\n",
      "\t TRAINING: ALS STEP: 21 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.48401537395273597\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.48039785745540403\n",
      "\t TRAINING:\t\tV step initial loss 0.397839910167743\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.3962201492316214\n",
      "\t TRAINING: ALS STEP: 22 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4794537178320587\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4759527342161609\n",
      "\t TRAINING:\t\tV step initial loss 0.39330031791561326\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.39179035271851437\n",
      "\t TRAINING: ALS STEP: 23 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4750368202926629\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.47164811838636994\n",
      "\t TRAINING:\t\tV step initial loss 0.38897248236018034\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.3875621816595805\n",
      "\t TRAINING: ALS STEP: 24 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4707593361414989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4674789230861014\n",
      "\t TRAINING:\t\tV step initial loss 0.3848430472314226\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.38352387202190263\n",
      "\t TRAINING: ALS STEP: 25 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4666165897039134\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4634406947681613\n",
      "\t TRAINING:\t\tV step initial loss 0.38090036656019066\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.37966499634220496\n",
      "\t TRAINING: ALS STEP: 26 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.46260435166080494\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4595293972290924\n",
      "\t TRAINING:\t\tV step initial loss 0.37713411937401525\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.37597617988091053\n",
      "\t TRAINING: ALS STEP: 27 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4587186899532393\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4557412681346583\n",
      "\t TRAINING:\t\tV step initial loss 0.3735350281310952\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.37244889196032205\n",
      "\t TRAINING: ALS STEP: 28 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4549558718789576\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4520727255465417\n",
      "\t TRAINING:\t\tV step initial loss 0.370094651859625\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.3690752915579196\n",
      "\t TRAINING: ALS STEP: 29 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4513123013053695\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.44852030864434433\n",
      "\t TRAINING:\t\tV step initial loss 0.366805233177271\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.3658481121252899\n",
      "\t TRAINING: ALS STEP: 30 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.44778447973609625\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.44508064158290045\n",
      "\t TRAINING:\t\tV step initial loss 0.36365958423992095\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.36276057482952695\n",
      "\t TRAINING: ALS STEP: 31 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4443689833711213\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4417504127795046\n",
      "\t TRAINING:\t\tV step initial loss 0.36065100087722723\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.3598063224445364\n",
      "\t TRAINING: ALS STEP: 32 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.44106245070366035\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4385263642929751\n",
      "\t TRAINING:\t\tV step initial loss 0.35777319718990513\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.35697936829464927\n",
      "\t TRAINING: ALS STEP: 33 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.43786157689044963\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4354052876233814\n",
      "\t TRAINING:\t\tV step initial loss 0.3550202550488507\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.35427405621505614\n",
      "\t TRAINING: ALS STEP: 34 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4347631123225527\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4323840234314996\n",
      "\t TRAINING:\t\tV step initial loss 0.3523865844906632\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.3516850286162881\n",
      "\t TRAINING: ALS STEP: 35 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.43176386365758745\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4294594634954681\n",
      "\t TRAINING:\t\tV step initial loss 0.3498668921209459\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.34920720054740095\n",
      "\t TRAINING: ALS STEP: 36 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.42886069615564837\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.42662855379163167\n",
      "\t TRAINING:\t\tV step initial loss 0.34745615543950287\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.3468357382335894\n",
      "\t TRAINING: ALS STEP: 37 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4260505365642345\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4238882979803993\n",
      "\t TRAINING:\t\tV step initial loss 0.3451496015788661\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.3445660409823823\n",
      "\t TRAINING: ALS STEP: 38 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4233303760748047\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4212357608480459\n",
      "\t TRAINING:\t\tV step initial loss 0.34294268936299593\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.34239372565409826\n",
      "\t TRAINING: ALS STEP: 39 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4206972730625441\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4186680714386933\n",
      "\t TRAINING:\t\tV step initial loss 0.34083109389208016\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.34031461310967515\n",
      "\t TRAINING: ALS STEP: 40 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4181483554480487\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4161824257333506\n",
      "\t TRAINING:\t\tV step initial loss 0.3388106930748162\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.33832471620594085\n",
      "\t TRAINING: ALS STEP: 41 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4156808226036932\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.41377608881338834\n",
      "\t TRAINING:\t\tV step initial loss 0.3368775556848975\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.33642022902178703\n",
      "\t TRAINING: ALS STEP: 42 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4132919467816941\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.41144639649723136\n",
      "\t TRAINING:\t\tV step initial loss 0.3350279306305174\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.3345975170807526\n",
      "\t TRAINING: ALS STEP: 43 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4109790740746815\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.40919075647058095\n",
      "\t TRAINING:\t\tV step initial loss 0.33325823720667924\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.3328531083949692\n",
      "\t TRAINING: ALS STEP: 44 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4087396249395025\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4070066489485609\n",
      "\t TRAINING:\t\tV step initial loss 0.33156505615868753\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.33118368519859137\n",
      "\t TRAINING: ALS STEP: 45 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4065710943255983\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4048916269173264\n",
      "\t TRAINING:\t\tV step initial loss 0.3299451214276572\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.3295860762702514\n",
      "\t TRAINING: ALS STEP: 46 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4044710514538088\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.40284331600600604\n",
      "\t TRAINING:\t\tV step initial loss 0.3283953124797333\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.3280572497670311\n",
      "\t TRAINING: ALS STEP: 47 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4024371392920807\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.4008594140395034\n",
      "\t TRAINING:\t\tV step initial loss 0.32691264714320134\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.32659430650927024\n",
      "\t TRAINING: ALS STEP: 48 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.4004670737727857\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.3989376903201398\n",
      "\t TRAINING:\t\tV step initial loss 0.3254942748941234\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.3251944736679353\n",
      "\t TRAINING: ALS STEP: 49 / 50\n",
      "\t TRAINING:\t\tU step initial loss 0.3985586427932177\n",
      "\t TRAINING:\t\tU Trained with alpha 0.1\n",
      "\t TRAINING:\t\tU step final loss 0.39707598468235517\n",
      "\t TRAINING:\t\tV step initial loss 0.3241374705432456\n",
      "\t TRAINING:\t\tV Trained with alpha 0.1\n",
      "\t TRAINING:\t\tV step final loss 0.3238550988154791\n",
      "DEMO RESULTS\n",
      "Avg. Reconstruction loss on the observed matrix entries before training (with random U and V) =0.4632949184950522\n",
      "Avg. Reconstruction loss on the observed matrix entries after training (with trained U and V) =0.10124568202646614\n",
      "VALIDATION: Avg. Reconstruction loss on the unobserved matrix entries before training (with random U and V) =0.4631410629503357\n",
      "VALIDATION: Avg. Reconstruction loss on the unobserved matrix entries after training (with trained U and V) =0.10361090460446255\n",
      "VALIDATION: Avg. Reconstruction loss on the all matrix entries before training (with random U and V) =0.46326605512420643\n",
      "VALIDATION: Avg. Reconstruction loss on the all matrix entries after training (with trained U and V) =0.1016893988683084\n",
      "Saving the processed matrices in demo_out.npz\n"
     ]
    }
   ],
   "source": [
    "%run main.py --run_demo --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faa7fd8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8e59c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Either the m or n value or the demo observed_fraction is missing. Using random values to run the demo.\n",
      "\n",
      "STARTING DEMO ..... \n",
      "\n",
      "Running the matrix completion demo.\n",
      "We will generate a random matrix of size M= [135x60], with 7 non-zero singular values (True SVD rank).\n",
      "0.9849628923318247 fraction of [135x60] entries will be masked out to simulate a partially observed matrix.\n",
      "We will use ALS procedure to estimate matrices U and V, such that ||M - U*transpose(V)||^2 is minimum.  will reconstruct the fully observed matrix.\n",
      "U and V will have rank equal to the user input --rank parameter =5.\n",
      "We will then compare the difference between the true unobserved entries of M and the predictions to validate our method.\n",
      "\n",
      "STARTING TRAINING ..... \n",
      "\n",
      "\t TRAINING: ALS STEP: 0 / 50\n",
      "\t TRAINING: ALS STEP: 1 / 50\n",
      "\t TRAINING: ALS STEP: 2 / 50\n",
      "\t TRAINING: ALS STEP: 3 / 50\n",
      "\t TRAINING: ALS STEP: 4 / 50\n",
      "\t TRAINING: ALS STEP: 5 / 50\n",
      "\t TRAINING: ALS STEP: 6 / 50\n",
      "\t TRAINING: ALS STEP: 7 / 50\n",
      "\t TRAINING: ALS STEP: 8 / 50\n",
      "\t TRAINING: ALS STEP: 9 / 50\n",
      "\t TRAINING: ALS STEP: 10 / 50\n",
      "\t TRAINING: ALS STEP: 11 / 50\n",
      "\t TRAINING: ALS STEP: 12 / 50\n",
      "\t TRAINING: ALS STEP: 13 / 50\n",
      "\t TRAINING: ALS STEP: 14 / 50\n",
      "\t TRAINING: ALS STEP: 15 / 50\n",
      "\t TRAINING: ALS STEP: 16 / 50\n",
      "\t TRAINING: ALS STEP: 17 / 50\n",
      "\t TRAINING: ALS STEP: 18 / 50\n",
      "\t TRAINING: ALS STEP: 19 / 50\n",
      "\t TRAINING: ALS STEP: 20 / 50\n",
      "\t TRAINING: ALS STEP: 21 / 50\n",
      "\t TRAINING: ALS STEP: 22 / 50\n",
      "\t TRAINING: ALS STEP: 23 / 50\n",
      "\t TRAINING: ALS STEP: 24 / 50\n",
      "\t TRAINING: ALS STEP: 25 / 50\n",
      "\t TRAINING: ALS STEP: 26 / 50\n",
      "\t TRAINING: ALS STEP: 27 / 50\n",
      "\t TRAINING: ALS STEP: 28 / 50\n",
      "\t TRAINING: ALS STEP: 29 / 50\n",
      "\t TRAINING: ALS STEP: 30 / 50\n",
      "\t TRAINING: ALS STEP: 31 / 50\n",
      "\t TRAINING: ALS STEP: 32 / 50\n",
      "\t TRAINING: ALS STEP: 33 / 50\n",
      "\t TRAINING: ALS STEP: 34 / 50\n",
      "\t TRAINING: ALS STEP: 35 / 50\n",
      "\t TRAINING: ALS STEP: 36 / 50\n",
      "\t TRAINING: ALS STEP: 37 / 50\n",
      "\t TRAINING: ALS STEP: 38 / 50\n",
      "\t TRAINING: ALS STEP: 39 / 50\n",
      "\t TRAINING: ALS STEP: 40 / 50\n",
      "\t TRAINING: ALS STEP: 41 / 50\n",
      "\t TRAINING: ALS STEP: 42 / 50\n",
      "\t TRAINING: ALS STEP: 43 / 50\n",
      "\t TRAINING: ALS STEP: 44 / 50\n",
      "\t TRAINING: ALS STEP: 45 / 50\n",
      "\t TRAINING: ALS STEP: 46 / 50\n",
      "\t TRAINING: ALS STEP: 47 / 50\n",
      "\t TRAINING: ALS STEP: 48 / 50\n",
      "\t TRAINING: ALS STEP: 49 / 50\n",
      "DEMO RESULTS\n",
      "Avg. Reconstruction loss on the observed matrix entries before training (with random U and V) =0.8697641297394634\n",
      "Avg. Reconstruction loss on the observed matrix entries after training (with trained U and V) =0.02964950081119748\n",
      "VALIDATION: Avg. Reconstruction loss on the unobserved matrix entries before training (with random U and V) =0.7385105555540147\n",
      "VALIDATION: Avg. Reconstruction loss on the unobserved matrix entries after training (with trained U and V) =1.0171558288636235\n",
      "VALIDATION: Avg. Reconstruction loss on the all matrix entries before training (with random U and V) =0.7404712570943158\n",
      "VALIDATION: Avg. Reconstruction loss on the all matrix entries after training (with trained U and V) =1.0024041911235813\n",
      "Saving the processed matrices in demo_out.npz\n"
     ]
    }
   ],
   "source": [
    "%run main.py --run_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e422dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
